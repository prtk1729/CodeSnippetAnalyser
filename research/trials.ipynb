{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for repo\n",
    "from git import Repo\n",
    "# for context-aware-splitting\n",
    "from langchain.text_splitter import Language\n",
    "# loader pertaining to load github repos\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import LanguageParser\n",
    "\n",
    "# std stuff for chunking\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# Embedding step requirement for embs\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "# for vectorstore\n",
    "from langchain.vectorstores import Chroma\n",
    "# GPT-3.5 Turbo\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# To sustain chat memory, chain is required when impelementing memory\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clone the repo and store in a given location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/prateek/RepoAnalyser/CodeSnippetAnalyser/research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<git.repo.base.Repo '/home/prateek/RepoAnalyser/CodeSnippetAnalyser/research/test_repo/.git'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!make_dir test_repo/\n",
    "target_path = \"./test_repo\"\n",
    "\n",
    "from git import Repo\n",
    "\n",
    "Repo.clone_from(url = \"https://github.com/prtk1729/ECommerceBot\", to_path=target_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic Document Loader and Language Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser is set, to understand the text syntaxes of a given language\n",
    "target_path = \"./test_repo\"\n",
    "loader = GenericLoader.from_filesystem(\n",
    "                                        target_path+\"/ecombot\",\n",
    "                                        glob = \"**/*\",\n",
    "                                        suffixes = [\".py\"], # multiple language in codebase here I can put other suffixes\n",
    "                                        parser = LanguageParser(language = Language.PYTHON, \n",
    "                                                                parser_threshold = 500) # min num oif tokens >= 500 to qualify as codebase \n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='import pandas as pd\\nfrom langchain_core.documents import Document # AstraDB and langchain \\n#require this format -> COnvert to this Document format\\n\\n\\ndef create_documents(list_of_dicts):\\n    \\'\\'\\'\\n        Returns a list of Document-objects\\n    \\'\\'\\'\\n    ret = []\\n    for le in list_of_dicts:    \\n        metadata = {\"product_name\": le[\"product_name\"]}\\n        page_content = le[\"review\"]\\n        ret.append( Document( page_content=page_content, metadata=metadata ) )\\n    return ret\\n\\n\\ndef data_converter():\\n    df = pd.read_csv(\"../data/flipkart_product_review.csv\")\\n    # print( df.head() )\\n    data = df[ [\"product_title\", \"review\"] ]\\n\\n    list_of_dict = []\\n    for index, row in data.iterrows():\\n        obj = {\\n                \"product_name\": row[\"product_title\"],\\n                \"review\": row[\"review\"] \\n              }\\n        list_of_dict.append(obj)\\n\\n    docs = create_documents(list_of_dict)\\n    return docs\\n\\n\\n\\nif __name__ == \"__main__\":\\n    docs = data_converter()\\n    print( docs )\\n', metadata={'source': 'test_repo/ecombot/data_converter.py', 'language': <Language.PYTHON: 'python'>}), Document(page_content='from langchain_core.output_parsers import StrOutputParser\\nfrom langchain_core.prompts import ChatPromptTemplate\\nfrom langchain_core.runnables import RunnablePassthrough\\nfrom langchain_openai import ChatOpenAI\\nfrom ecombot.ingest import ingest_data\\n\\n\\ndef generation(vstore):\\n    retriever = vstore.as_retriever(search_kwargs={\"k\": 3})\\n\\n    PRODUCT_BOT_TEMPLATE = \"\"\"\\n    Your ecommercebot bot is an expert in product recommendations and customer queries.\\n    It analyzes product titles and reviews to provide accurate and helpful responses.\\n    Ensure your answers are relevant to the product context and refrain from off-topic responses.\\n    Your responses should be concise and informative. In case, user asks for generic queries \\n    unrelated to the products, use your own knowledge to answer them.\\n\\n    CONTEXT:\\n    {context}\\n\\n    QUESTION: {question}\\n\\n    YOUR ANSWER:\\n    \\n    \"\"\"\\n\\n\\n    prompt = ChatPromptTemplate.from_template(PRODUCT_BOT_TEMPLATE)\\n\\n    llm = ChatOpenAI()\\n\\n    chain = (\\n        {\"context\": retriever, \"question\": RunnablePassthrough()}\\n        | prompt\\n        | llm\\n        | StrOutputParser()\\n    )\\n\\n    return chain\\n\\nif __name__==\\'__main__\\':\\n    vstore = ingest_data(\"Already Ingested to VStore\")\\n    chain  = generation(vstore)\\n    print(chain.invoke(\"Suggest me the best bluetooth earphone?\"))\\n    # I would recommend the OnePlus Bullets Wireless Z Bass Edition Bluetooth Headset\\n    # as it is highly rated for its sound quality, comfort, durability, and battery life.\\n    \\n    \\n    ', metadata={'source': 'test_repo/ecombot/retrieval_and_generation.py', 'language': <Language.PYTHON: 'python'>}), Document(page_content='from langchain_astradb import AstraDBVectorStore\\nfrom langchain_openai import OpenAIEmbeddings\\nfrom dotenv import load_dotenv\\nimport pandas as pd\\nimport os\\nfrom ecombot.data_converter import data_converter\\n\\nload_dotenv()\\n\\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\\nASTRA_DB_API_ENDPOINT = os.getenv(\"ASTRA_DB_API_ENDPOINT\")\\nASTRA_DB_APPLICATION_TOKEN = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\\nASTRA_DB_KEYSPACE = os.getenv(\"ASTRA_DB_KEYSPACE\")\\n\\nembedding = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\\n\\ndef ingest_data(status):\\n    \\'\\'\\'\\n    Creates a vector DB in Astra ans store all the documents there\\n    with the collection_name as given below\\n    \\'\\'\\'\\n    vstore = AstraDBVectorStore(\\\\\\n                                embedding = embedding,\\n                                collection_name=\"ecomChatBot\",\\n                                api_endpoint=ASTRA_DB_API_ENDPOINT,\\n                                token=ASTRA_DB_APPLICATION_TOKEN,\\n                                namespace=ASTRA_DB_KEYSPACE\\n                                )\\n\\n    storage = status\\n    if storage == None: # convert and add to vstore only once\\n        docs = data_converter() # list of Document() -> this format send to astra\\n        inserted_ids = vstore.add_documents(docs)\\n    else:\\n        return vstore\\n    return inserted_ids, vstore\\n    \\n\\nif __name__ == \"__main__\":\\n    inserted_ids, vstore =ingest_data(None)\\n    print(f\"\\\\nInserted {len(inserted_ids)} documents.\")\\n\\n    # Do the similarity search on some text as Question\\n    results = vstore.similarity_search(\"Suggest a low budget sound basshead.\")\\n    for res in results:\\n        print(f\"* {res.page_content} [{res.metadata}]\")\\n\\n', metadata={'source': 'test_repo/ecombot/ingest.py', 'language': <Language.PYTHON: 'python'>}), Document(page_content='', metadata={'source': 'test_repo/ecombot/__init__.py', 'language': <Language.PYTHON: 'python'>})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( documents )\n",
    "# since 4 py files, 4 Document-elements in the list\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context-Aware Splitting\n",
    "- Basically, we tag chunks of same functions\n",
    "- Align the chunks along with the tag-names as function-names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_splitter = RecursiveCharacterTextSplitter.from_language( language = Language.PYTHON,\\\n",
    "                                                            chunk_size = 2000, # depends on window-size of loaded LLM\n",
    "                                                            chunk_overlap = 200\n",
    "                                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = doc_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[Document(page_content='import pandas as pd\\nfrom langchain_core.documents import Document # AstraDB and langchain \\n#require this format -> COnvert to this Document format\\n\\n\\ndef create_documents(list_of_dicts):\\n    \\'\\'\\'\\n        Returns a list of Document-objects\\n    \\'\\'\\'\\n    ret = []\\n    for le in list_of_dicts:    \\n        metadata = {\"product_name\": le[\"product_name\"]}\\n        page_content = le[\"review\"]\\n        ret.append( Document( page_content=page_content, metadata=metadata ) )\\n    return ret\\n\\n\\ndef data_converter():\\n    df = pd.read_csv(\"../data/flipkart_product_review.csv\")\\n    # print( df.head() )\\n    data = df[ [\"product_title\", \"review\"] ]\\n\\n    list_of_dict = []\\n    for index, row in data.iterrows():\\n        obj = {\\n                \"product_name\": row[\"product_title\"],\\n                \"review\": row[\"review\"] \\n              }\\n        list_of_dict.append(obj)\\n\\n    docs = create_documents(list_of_dict)\\n    return docs\\n\\n\\n\\nif __name__ == \"__main__\":\\n    docs = data_converter()\\n    print( docs )', metadata={'source': 'test_repo/ecombot/data_converter.py', 'language': <Language.PYTHON: 'python'>}), Document(page_content='from langchain_core.output_parsers import StrOutputParser\\nfrom langchain_core.prompts import ChatPromptTemplate\\nfrom langchain_core.runnables import RunnablePassthrough\\nfrom langchain_openai import ChatOpenAI\\nfrom ecombot.ingest import ingest_data\\n\\n\\ndef generation(vstore):\\n    retriever = vstore.as_retriever(search_kwargs={\"k\": 3})\\n\\n    PRODUCT_BOT_TEMPLATE = \"\"\"\\n    Your ecommercebot bot is an expert in product recommendations and customer queries.\\n    It analyzes product titles and reviews to provide accurate and helpful responses.\\n    Ensure your answers are relevant to the product context and refrain from off-topic responses.\\n    Your responses should be concise and informative. In case, user asks for generic queries \\n    unrelated to the products, use your own knowledge to answer them.\\n\\n    CONTEXT:\\n    {context}\\n\\n    QUESTION: {question}\\n\\n    YOUR ANSWER:\\n    \\n    \"\"\"\\n\\n\\n    prompt = ChatPromptTemplate.from_template(PRODUCT_BOT_TEMPLATE)\\n\\n    llm = ChatOpenAI()\\n\\n    chain = (\\n        {\"context\": retriever, \"question\": RunnablePassthrough()}\\n        | prompt\\n        | llm\\n        | StrOutputParser()\\n    )\\n\\n    return chain\\n\\nif __name__==\\'__main__\\':\\n    vstore = ingest_data(\"Already Ingested to VStore\")\\n    chain  = generation(vstore)\\n    print(chain.invoke(\"Suggest me the best bluetooth earphone?\"))\\n    # I would recommend the OnePlus Bullets Wireless Z Bass Edition Bluetooth Headset\\n    # as it is highly rated for its sound quality, comfort, durability, and battery life.', metadata={'source': 'test_repo/ecombot/retrieval_and_generation.py', 'language': <Language.PYTHON: 'python'>}), Document(page_content='from langchain_astradb import AstraDBVectorStore\\nfrom langchain_openai import OpenAIEmbeddings\\nfrom dotenv import load_dotenv\\nimport pandas as pd\\nimport os\\nfrom ecombot.data_converter import data_converter\\n\\nload_dotenv()\\n\\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\\nASTRA_DB_API_ENDPOINT = os.getenv(\"ASTRA_DB_API_ENDPOINT\")\\nASTRA_DB_APPLICATION_TOKEN = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\\nASTRA_DB_KEYSPACE = os.getenv(\"ASTRA_DB_KEYSPACE\")\\n\\nembedding = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\\n\\ndef ingest_data(status):\\n    \\'\\'\\'\\n    Creates a vector DB in Astra ans store all the documents there\\n    with the collection_name as given below\\n    \\'\\'\\'\\n    vstore = AstraDBVectorStore(\\\\\\n                                embedding = embedding,\\n                                collection_name=\"ecomChatBot\",\\n                                api_endpoint=ASTRA_DB_API_ENDPOINT,\\n                                token=ASTRA_DB_APPLICATION_TOKEN,\\n                                namespace=ASTRA_DB_KEYSPACE\\n                                )\\n\\n    storage = status\\n    if storage == None: # convert and add to vstore only once\\n        docs = data_converter() # list of Document() -> this format send to astra\\n        inserted_ids = vstore.add_documents(docs)\\n    else:\\n        return vstore\\n    return inserted_ids, vstore\\n    \\n\\nif __name__ == \"__main__\":\\n    inserted_ids, vstore =ingest_data(None)\\n    print(f\"\\\\nInserted {len(inserted_ids)} documents.\")\\n\\n    # Do the similarity search on some text as Question\\n    results = vstore.similarity_search(\"Suggest a low budget sound basshead.\")\\n    for res in results:\\n        print(f\"* {res.page_content} [{res.metadata}]\")', metadata={'source': 'test_repo/ecombot/ingest.py', 'language': <Language.PYTHON: 'python'>})]\n"
     ]
    }
   ],
   "source": [
    "print(len( texts ))\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"xxxxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings( disallowed_special=() ) # ignore special chars in codebase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Base (VectorDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents( documents=texts, # cas -> list_of_docs\n",
    "                      embedding= embeddings, # embedding object\n",
    "                       persist_directory=\"./data\" ) # creates this data directory to store the vectors\n",
    "\n",
    "# create the local db, inside persist_dir we can find the embs\n",
    "vectordb.persist() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(model_name='gpt-4') # Not using as it will charge a lot\n",
    "llm = ChatOpenAI() # default i.e 3.5 turbo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the history of the chat\n",
    "- Creates a buffer memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryMemory( llm = llm, \\\n",
    "                                   memory_key=\"chat_history\",\n",
    "                                   return_messages=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA Wrapper\n",
    "- retriver is the vectordb's retriever\n",
    "- search_kwargs -> 3 : To give 3 line result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = ConversationalRetrievalChain.from_llm( llm = llm,\\\n",
    "                                           retriever=vectordb.as_retriever(search_type=\"mmr\",\n",
    "                                                                           search_kwargs={\"k\": 3}),\n",
    "                                            memory=memory )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QnA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Elaborate more on the functionality of generation function, line by line?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 9, updating n_results = 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Let's break down the functionality of the `generation` function line by line:\n",
      "\n",
      "1. The function starts by defining a retriever using the vector store (`vstore`) to retrieve relevant information based on the search parameters provided.\n",
      "\n",
      "2. It then sets up a template for the product bot chat prompt. The template includes a specific context, the user's question, and a placeholder for the bot's answer.\n",
      "\n",
      "3. It initializes an instance of the OpenAI language model for chat responses.\n",
      "\n",
      "4. It creates a chain of operations that involve retrieving context and question, passing them through the prompt template, feeding them into the OpenAI chat model, and finally parsing the output as a string.\n",
      "\n",
      "5. The function returns the chain of operations that can be invoked to generate responses to user queries related to product recommendations and customer queries.\n",
      "\n",
      "In summary, the `generation` function sets up a pipeline for processing user queries related to product recommendations using a vector store retriever, a chat prompt template, and an OpenAI language model for generating responses.\n"
     ]
    }
   ],
   "source": [
    "result = qa(question)\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
